{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JK0C82bytycZ",
    "outputId": "7d40cb46-6aa1-4bd0-b335-dbf8726f92ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7CZVJCbz5CsX"
   },
   "source": [
    "## Autoencoder (encoder-decoder) for X-ray Image\n",
    "Here we will design an autoencoder to reconstruct 3D image from 2D X-ray images. First, we will feed the X-ray images to the network. In 3D reconstruction, our target will be a volume of images. \n",
    "\n",
    "So, <br>input of the model: 2D X-ray images \n",
    "<br>target of the model: Volume of the images\n",
    "\n",
    "This network can be divided into three sections -\n",
    "\n",
    "                                   Representation network \n",
    "                                   Transformation network\n",
    "                                   Generation network\n",
    "\n",
    "Representation network: It downsamples the feature maps. But, while downsampling, we will increase the no. of feature maps by increasing the no. of convolutional filters.\n",
    "\n",
    "Transformation network: It converts the 2D feature maps into 3D feature maps.\n",
    "\n",
    "Generation network: Here we will upsample the feature maps and finally will convert to a stack of 2D images.\n",
    "\n",
    "v5 Update:\n",
    "- Checkpoint is introduced\n",
    "- Reducing learning rate is introduced\n",
    "\n",
    "v6 Update:\n",
    "- Plotting introduced\n",
    "\n",
    "v7 Update:\n",
    "- training dataset is resized along the z-axis\n",
    "\n",
    "v7_5 Update:\n",
    "- Moving to new format: channel x depth x height x width. (Previously it was - depth x height x width x channel)\n",
    "- Channel first format\n",
    "\n",
    "v10_1 Update:\n",
    "- This code is for segmented vertebrae. New code for data preprocessing is introduced\n",
    "\n",
    "v10_2 Update:\n",
    "- Image stacking is introduced\n",
    "\n",
    "v10_3 Update:\n",
    "- Image stacking and not-stacking are integrated together\n",
    "\n",
    "v10_4 Update:\n",
    "- New boolean variable `stack` is introduced. For multiple projections, `stack` is `True`. \n",
    "\n",
    "v10_5 Update:\n",
    "- Custom loss function is introduced. It considers both `mse` and `psnr` in calculating loss.\n",
    "\n",
    "v10_6 Update:\n",
    "- Custom loss functions are added in `monitor`\n",
    "\n",
    "v10_7 Update:\n",
    "- two axes projections are used during training\n",
    "\n",
    "v10_8 Update:\n",
    "- Created a user friendly function that can handle both single and multi projections\n",
    "- shuffling of image names added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ULPOdJs5CsX"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, Conv3D, UpSampling2D, MaxPooling2D, Conv2DTranspose, Conv3DTranspose\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import BatchNormalization, Add, Reshape\n",
    "from tensorflow.keras.backend import squeeze, transpose, reshape\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from skimage.measure import compare_mse, compare_nrmse, compare_psnr, compare_ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio\n",
    "import scipy.io as sio\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "73gZRgcQ5Csa"
   },
   "source": [
    "### Prepare training images and corresponding targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-8-dtSK5Csb"
   },
   "source": [
    "Data and targets will be preprocessed using the funtion `create_data`. Details of it will be found in `prepareData.py`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KDLaHQ1p5Csb"
   },
   "outputs": [],
   "source": [
    "# Parameters \n",
    "# filters = [256, 512, 1024, 2048, 4096, 128, 64] # 128 and 64 are used only for deconv\n",
    "filters = [192, 384, 768, 1536, 3072, 96, 48]\n",
    "# filters = [128, 256, 512, 1024, 2048, 64, 32]\n",
    "# filters = [32, 64, 128, 256, 512, 16, 8]\n",
    "\n",
    "# depth = 120            # Depth means images along the z-axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7vLyw83H5Cse"
   },
   "source": [
    "Load the training images saved in `.mat` format. It is created using `readImage.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3R-UjWyg353C"
   },
   "source": [
    "Set directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C1LjpQGf30IV",
    "outputId": "fd10da37-80f0-428d-e4cc-49021635df4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vertebra08', 'vertebra09', 'vertebra11', 'vertebra12', 'vertebra13', 'vertebra14']\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Image location information:\n",
    "X-ray images are stored in the following way -\n",
    "\n",
    "    xray -------> train --> several vertebrae folders --> images inside each folder\n",
    "       |\n",
    "        --------> test --> several vertebrae folders --> images inside each folder\n",
    "    \n",
    "CTs are stored in the following way - \n",
    "    ct -------> train --> several .mat files\n",
    "     |\n",
    "      --------> test --> several .mat files\n",
    "'''\n",
    "# xRay location\n",
    "trainDir = '/content/drive/My Drive/3Dreconstruction/xray/vertebra/xray-x-y-axes' #vertebra-xray\n",
    "\n",
    "# Target (CT) location\n",
    "trainCtDir = '/content/drive/My Drive/3Dreconstruction/ct/vertebra/train'  #vertebra-CT\n",
    "\n",
    "#************ Uncomment if you want to create trainSubset AUTOMATICALLY\n",
    "# trainSubset = [item for item in os.listdir(trainDir)]   # folders inside the train folder\n",
    "# trainSubset = trainSubset[0:30]\n",
    "#************ Uncomment if you want to create trainSubset MANUALLY\n",
    "trainSubset = ['vertebra08','vertebra09','vertebra11','vertebra12','vertebra13','vertebra14']\n",
    "\n",
    "print(trainSubset)\n",
    "print(len(trainSubset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OL3g8QIA4L8q"
   },
   "source": [
    "Create projection indices which will be stacked together later\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bveIFIcg4Kxr",
    "outputId": "e27381fe-7175-4045-a07f-b2e41fc26f48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of training images per object:  36\n",
      "No. of objects:  6\n",
      "Total no. of training images:  216\n",
      "[['x_axis_deg_000'], ['x_axis_deg_010'], ['x_axis_deg_020'], ['x_axis_deg_030'], ['x_axis_deg_040'], ['x_axis_deg_050'], ['x_axis_deg_060'], ['x_axis_deg_070'], ['x_axis_deg_080'], ['x_axis_deg_090'], ['x_axis_deg_100'], ['x_axis_deg_110'], ['x_axis_deg_120'], ['x_axis_deg_130'], ['x_axis_deg_140'], ['x_axis_deg_150'], ['x_axis_deg_160'], ['x_axis_deg_170'], ['x_axis_deg_180'], ['x_axis_deg_190'], ['x_axis_deg_200'], ['x_axis_deg_210'], ['x_axis_deg_220'], ['x_axis_deg_230'], ['x_axis_deg_240'], ['x_axis_deg_250'], ['x_axis_deg_260'], ['x_axis_deg_270'], ['x_axis_deg_280'], ['x_axis_deg_290'], ['x_axis_deg_300'], ['x_axis_deg_310'], ['x_axis_deg_320'], ['x_axis_deg_330'], ['x_axis_deg_340'], ['x_axis_deg_350']]\n"
     ]
    }
   ],
   "source": [
    "# Create projection indices which will be stacked together later\n",
    "'''\n",
    "Let's say, we want to create a series of stacks as follows - \n",
    "[\n",
    "['x_axis_deg_000', 'x_axis_deg_030', 'x_axis_deg_060'], ['x_axis_deg_010', 'x_axis_deg_040', 'x_axis_deg_070'], ......\n",
    "['y_axis_deg_000', 'y_axis_deg_030', 'x_axis_deg_060'], ['y_axis_deg_010', 'y_axis_deg_040', 'y_axis_deg_070'], ......\n",
    "]\n",
    "\n",
    "So, first we need the axes names that we will be using. We define them in a list called 'axis_name'.\n",
    "\n",
    "Then, we need a starting projection angle. We call it 'startAngle'. For the above example, startAngle = 0\n",
    "\n",
    "We then need to know how many projections are we going to stack together. We call it 'noOfPrjtn'. For the above example,\n",
    "it is 3. So, each stack will have 3 projections inside. \n",
    "\n",
    "Next, we need to increment the projection angle for the existing stack. We call it 'prjtnAngleIncr'. For the above example, \n",
    "it is 30. So, the projections are 0-deg, 30-deg, and 60-deg. \n",
    "\n",
    "Now, what will be the starting projection for the next stack? We define it as 'previous starting angle + an increment'.\n",
    "The 'incr' variable is used to do so. For the above example, it is 10. So, the starting angle for the 2nd stack will be\n",
    "0 + 10 = 10. Likewise, for the 3rd stack, it will be 10+10 = 20\n",
    "\n",
    "Also, we need to define a stopping critera to stop making stacks. We did this using 'maxStartAngle'. For instance, when \n",
    "maxStartAngle is set to 90, it means that while creating a stack whose starting angle is larger than 90, it will\n",
    "not create that stack, rather will exit from stacking.  \n",
    "\n",
    "We have also added an error message if any angle becomes more than 360-deg.\n",
    "\n",
    "Finally, x-ray images are stored in the following format: x_axis_deg_xxx.png. For instance: x_axis_degree_125.png'. \n",
    "So, we need to create this 3-digit projection angle. We did this using 'zfill'.\n",
    "'''\n",
    "# axis_name = ['x_axis_deg_', 'y_axis_deg_']\n",
    "axis_name = ['x_axis_deg_']\n",
    "startAngle = 0                                     \n",
    "noOfPrjtn = 1\n",
    "prjtnAngleIncr = 90           # Increase projection angle within the stack\n",
    "incr = 10                     # Increase starting angle for the next stack                                           \n",
    "maxStartAngle = 350            # Max starting angle allowed for stacking\n",
    "\n",
    "stackIdx = []\n",
    "temp = []\n",
    "\n",
    "storeIntStartAngle = startAngle                                     # Store initial starting angle\n",
    "for axis in axis_name:\n",
    "  while (startAngle <= maxStartAngle):\n",
    "    moveAngle = startAngle\n",
    "    for i in range(noOfPrjtn):\n",
    "      strName = axis + str(moveAngle).zfill(3)                      # Convert it to 3-digit\n",
    "      temp.append(strName)\n",
    "      assert moveAngle <= 360, \"Angle should not cross 360 degree\"  # Error msg, if any angle>360\n",
    "      moveAngle += prjtnAngleIncr\n",
    "\n",
    "    startAngle += incr\n",
    "\n",
    "    stackIdx.append(temp)\n",
    "    temp = []\n",
    "  startAngle = storeIntStartAngle\n",
    "\n",
    "print('No. of training images per object: ', len(stackIdx))\n",
    "print('No. of objects: ', len(trainSubset))\n",
    "print('Total no. of training images: ', len(stackIdx)*len(trainSubset))\n",
    "print(stackIdx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jmzIrOhSc63v"
   },
   "source": [
    "Shuffle stackIdx (Optional)</br>\n",
    "- If you want to shuffle stackIdx, set the `shuffle` variable to `True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yuzE5BaZdbLr",
    "outputId": "91f8dd7c-025e-4d50-878e-812f4bfd92a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of training images per vertebra:  36\n",
      "[['x_axis_deg_220'], ['x_axis_deg_060'], ['x_axis_deg_250'], ['x_axis_deg_150'], ['x_axis_deg_210'], ['x_axis_deg_350'], ['x_axis_deg_330'], ['x_axis_deg_300'], ['x_axis_deg_260'], ['x_axis_deg_070'], ['x_axis_deg_340'], ['x_axis_deg_100'], ['x_axis_deg_240'], ['x_axis_deg_160'], ['x_axis_deg_000'], ['x_axis_deg_110'], ['x_axis_deg_040'], ['x_axis_deg_080'], ['x_axis_deg_190'], ['x_axis_deg_180'], ['x_axis_deg_010'], ['x_axis_deg_140'], ['x_axis_deg_290'], ['x_axis_deg_130'], ['x_axis_deg_050'], ['x_axis_deg_200'], ['x_axis_deg_310'], ['x_axis_deg_230'], ['x_axis_deg_120'], ['x_axis_deg_020'], ['x_axis_deg_170'], ['x_axis_deg_280'], ['x_axis_deg_270'], ['x_axis_deg_090'], ['x_axis_deg_030'], ['x_axis_deg_320']]\n"
     ]
    }
   ],
   "source": [
    "shuffle = True\n",
    "if shuffle is True:\n",
    "  perm = np.random.permutation(len(stackIdx))\n",
    "  shuffleStackIdx = []\n",
    "  for i in range(len(stackIdx)):\n",
    "    shuffleStackIdx.append(stackIdx[perm[i]])\n",
    "  stackIdx = shuffleStackIdx\n",
    "\n",
    "print('No. of training images per vertebra: ', len(stackIdx))\n",
    "print(stackIdx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Krm8YVrb4hxb"
   },
   "source": [
    "Create a function to append xrays and CTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "73QQ0ulX5Cse"
   },
   "outputs": [],
   "source": [
    "# Create a function to append xrays and CTs\n",
    "'''\n",
    "The following function is to store xray images and their corresponding targets.\n",
    "The output is a list --> [xray, ct]\n",
    "\n",
    "imgSize is an optional argument. If you want to resize then use imgSize.\n",
    "For example, imgSize = (128,128)\n",
    "'''\n",
    "def create_data(trainDir, trainCtDir, trainSubset, stkIdx=None, imgSize=None):\n",
    "    output = []\n",
    "    noOfPrjtn = len(stkIdx[0])            # No. of projections in a single stack\n",
    "\n",
    "    for subset in trainSubset:\n",
    "        matName = subset + '.mat'\n",
    "        Ct = sio.loadmat(os.path.join(trainCtDir, matName))\n",
    "        key = sorted(Ct.keys())\n",
    "        trainCt = Ct[key[3]]  \n",
    "\n",
    "        for idx in range(len(stkIdx)):    # Looping around no. of stacks\n",
    "          stkImg = []                     # This will append all projections for a single stack \n",
    "          for i in range(noOfPrjtn):      # Looping around no. projections in a stack\n",
    "            ext = '.png'                  # Extension\n",
    "            stkName = stkIdx[idx][i] + ext \n",
    "            if (ext == '.png'):          \n",
    "              stk = cv2.imread(os.path.join(trainDir, subset, stkName), 0)\n",
    "            elif (ext == '.mat'):\n",
    "              loadStk = sio.loadmat(os.path.join(trainDir, subset, stkName))\n",
    "              key = sorted(loadStk.keys())\n",
    "              stk = loadStk[key[3]]\n",
    "\n",
    "            if imgSize is not None:\n",
    "              stk = cv2.resize(stk, imgSize)\n",
    "            stkImg.append(stk)\n",
    "          \n",
    "          # stkImg = np.array(stkImg, dtype='uint8')\n",
    "          stkImg = np.array(stkImg)\n",
    "          output.append([stkImg, trainCt])           \n",
    "\n",
    "    return output            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q3ZylRwX4nOL"
   },
   "source": [
    "Prepare training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_wvivoRS4lcC",
    "outputId": "a7005b35-886c-4bf7-9b64-3f865239352f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train:  (216, 1, 128, 128)\n",
      "Shape of Y_train:  (216, 50, 128, 128)\n",
      "Depth of the CT:  50\n"
     ]
    }
   ],
   "source": [
    "# Prepare training data\n",
    "# imgSize = (128,128)    \n",
    "train = create_data(trainDir, trainCtDir, trainSubset, stackIdx, imgSize=None)  # For stacked multiple projections\n",
    "\n",
    "X_train = []\n",
    "Y_train = []\n",
    "\n",
    "for feature, gt in train:\n",
    "    X_train.append(feature)\n",
    "    Y_train.append(gt)\n",
    "    \n",
    "X_train = np.array(X_train)                 \n",
    "\n",
    "if len(X_train.shape) < 4:\n",
    "  X_train = X_train[:,np.newaxis,:,:]       # Creating channel first\n",
    "\n",
    "Y_train = np.array(Y_train)\n",
    "Y_train = np.moveaxis(Y_train, -1, 1)       # Creating channel first\n",
    "\n",
    "print('Shape of X_train: ', X_train.shape)  # Shape: N, viewIdx or channel, sizeX, sizeY\n",
    "print('Shape of Y_train: ', Y_train.shape)\n",
    "\n",
    "depth = Y_train.shape[1]\n",
    "print('Depth of the CT: ', depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JJJdOICX5Csg"
   },
   "outputs": [],
   "source": [
    "# Normalize the feature\n",
    "# X_train = X_train/255 \n",
    "X_train = X_train - np.min(X_train)\n",
    "X_train = X_train / np.max(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "as0MLuVA5Csl"
   },
   "outputs": [],
   "source": [
    "# Normalize the target\n",
    "# target = Y_train/255\n",
    "target = Y_train\n",
    "target = target - np.min(target)\n",
    "target = target / np.max(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KNIjVbcd5Csq"
   },
   "source": [
    "## Encoder-Decoder (Autoencoder)\n",
    "- We will use functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2t2Cgyhr5Csq"
   },
   "source": [
    "## Representation network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JIcNxx7U5Csq"
   },
   "outputs": [],
   "source": [
    "inputImg = Input(shape=X_train.shape[1:], name='input_img') #define input layer\n",
    "\n",
    "##############################################################################\n",
    "# 1st conv layer\n",
    "conv1 = Conv2D(filters[0], (4,4), strides=(2,2), padding='same', name='conv1', data_format='channels_first')(inputImg) \n",
    "conv1_BN = BatchNormalization()(conv1) \n",
    "conv1_out = Activation('relu')(conv1_BN)\n",
    "\n",
    "# 2nd conv layer\n",
    "conv2 = Conv2D(filters[0], (3,3), strides=(1,1), padding='same', name='conv2', data_format='channels_first')(conv1_out)\n",
    "conv2_BN = BatchNormalization()(conv2)\n",
    "\n",
    "# Add conv1 and conv2_BN (shortcut path)\n",
    "add_conv1_2 = Add()([conv1_out, conv2_BN])\n",
    "\n",
    "# Residual output of 1st and 2nd layers\n",
    "conv2_out = Activation('relu')(add_conv1_2)\n",
    "\n",
    "###############################################################################\n",
    "# 3rd conv layer\n",
    "conv3 = Conv2D(filters[1], (4,4), strides=(2,2), padding='same', name='conv3', data_format='channels_first')(conv2_out) \n",
    "conv3_BN = BatchNormalization()(conv3) \n",
    "conv3_out = Activation('relu')(conv3_BN)\n",
    "\n",
    "# 4th conv layer\n",
    "conv4 = Conv2D(filters[1], (3,3), strides=(1,1), padding='same', name='conv4', data_format='channels_first')(conv3_out)\n",
    "conv4_BN = BatchNormalization()(conv4)\n",
    "\n",
    "# Add conv3 and conv4_BN (shortcut path)\n",
    "add_conv3_4 = Add()([conv3_out, conv4_BN])\n",
    "\n",
    "# Residual output of 3rd and 4th layers\n",
    "conv4_out = Activation('relu')(add_conv3_4)\n",
    "\n",
    "###############################################################################\n",
    "# 5th conv layer\n",
    "conv5 = Conv2D(filters[2], (4,4), strides=(2,2), padding='same', name='conv5', data_format='channels_first')(conv4_out) \n",
    "conv5_BN = BatchNormalization()(conv5) \n",
    "conv5_out = Activation('relu')(conv5_BN)\n",
    "\n",
    "# 6th conv layer\n",
    "conv6 = Conv2D(filters[2], (3,3), strides=(1,1), padding='same', name='conv6', data_format='channels_first')(conv5_out)\n",
    "conv6_BN = BatchNormalization()(conv6)\n",
    "\n",
    "# Add conv5 and conv6_BN (shortcut path)\n",
    "add_conv5_6 = Add()([conv5_out, conv6_BN])\n",
    "\n",
    "# Residual output of 5th and 6th layers\n",
    "conv6_out = Activation('relu')(add_conv5_6)\n",
    "\n",
    "###############################################################################\n",
    "# 7th conv layer\n",
    "conv7 = Conv2D(filters[3], (4,4), strides=(2,2), padding='same', name='conv7', data_format='channels_first')(conv6_out) \n",
    "conv7_BN = BatchNormalization()(conv7) \n",
    "conv7_out = Activation('relu')(conv7_BN)\n",
    "\n",
    "# 8th conv layer\n",
    "conv8 = Conv2D(filters[3], (3,3), strides=(1,1), padding='same', name='conv8', data_format='channels_first')(conv7_out)\n",
    "conv8_BN = BatchNormalization()(conv8)\n",
    "\n",
    "# Add conv7 and conv8_BN (shortcut path)\n",
    "add_conv7_8 = Add()([conv7_out, conv8_BN])\n",
    "\n",
    "# Residual output of 7th and 8th layers\n",
    "conv8_out = Activation('relu')(add_conv7_8)\n",
    "\n",
    "###############################################################################\n",
    "# 9th conv layer\n",
    "conv9 = Conv2D(filters[4], (4,4), strides=(2,2), padding='same', name='conv9', data_format='channels_first')(conv8_out) \n",
    "conv9_BN = BatchNormalization()(conv9) \n",
    "conv9_out = Activation('relu')(conv9_BN)\n",
    "\n",
    "# 10th conv layer\n",
    "conv10 = Conv2D(filters[4], (3,3), strides=(1,1), padding='same', name='conv10', data_format='channels_first')(conv9_out)\n",
    "conv10_BN = BatchNormalization()(conv10)\n",
    "\n",
    "# Add conv9 and conv10_BN (shortcut path)\n",
    "add_conv9_10 = Add()([conv9_out, conv10_BN])\n",
    "\n",
    "# Residual output of 9th and 10th layers\n",
    "conv10_out = Activation('relu')(add_conv9_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pgTMDK1H5Css"
   },
   "outputs": [],
   "source": [
    "# Create autoencoder representation model\n",
    "autoEncRep = Model(inputs=inputImg, outputs=conv10_out, name='xray_autoencoder_representation_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7SJyhIzW5Csv"
   },
   "outputs": [],
   "source": [
    "# autoEncRep.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uZ1MtLFo5Csx"
   },
   "source": [
    "## Transformation network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W1Fw39nO5Csy"
   },
   "outputs": [],
   "source": [
    "trans1 = Conv2D(filters[4], (1,1), padding='same', activation='relu', name='trans1', data_format='channels_first')(conv10_out)\n",
    "trans1_reshape = Reshape([filters[3],2,trans1.shape[2],trans1.shape[3]])(trans1)\n",
    "trans_out = Conv3D(filters[3], kernel_size=1, strides=(1,1,1), padding='same', activation='relu', name='trans_out', data_format='channels_first')(trans1_reshape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oZmwIsmL5Cs0"
   },
   "outputs": [],
   "source": [
    "autoEncTrans = Model(inputs=inputImg, outputs=trans_out, name='xray_autoencoder_transformation_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4WAR69od5Cs2"
   },
   "outputs": [],
   "source": [
    "# autoEncTrans.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lZUUEoO95Cs3",
    "outputId": "23895959-a137-4ddb-9f9e-2d50530965f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'trans_out/Relu:0' shape=(None, 1536, 2, 4, 4) dtype=float32>"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "72tGKh8C5Cs6"
   },
   "source": [
    "## Generation network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oaA2Nq8J5Cs6"
   },
   "outputs": [],
   "source": [
    "##########Deconvolution###############################\n",
    "#1024\n",
    "gen1 = Conv3DTranspose(filters[2], kernel_size=4, strides=(2,2,2), padding='same', name='gen1', data_format='channels_first')(trans_out)\n",
    "gen1_BN = BatchNormalization()(gen1) \n",
    "gen1_out = Activation('relu')(gen1_BN)\n",
    "\n",
    "#512\n",
    "gen2 = Conv3DTranspose(filters[1], kernel_size=4, strides=(2,2,2), padding='same', name='gen2', data_format='channels_first')(gen1_out)\n",
    "gen2_BN = BatchNormalization()(gen2) \n",
    "gen2_out = Activation('relu')(gen2_BN)\n",
    "\n",
    "gen3 = Conv3DTranspose(filters[1], kernel_size=3, strides=(1,1,1), padding='same', name='gen3', data_format='channels_first')(gen2_out)\n",
    "gen3_BN = BatchNormalization()(gen3) \n",
    "gen3_out = Activation('relu')(gen3_BN)\n",
    "\n",
    "#256\n",
    "gen4 = Conv3DTranspose(filters[0], kernel_size=4, strides=(2,2,2), padding='same', name='gen4', data_format='channels_first')(gen3_out)\n",
    "gen4_BN = BatchNormalization()(gen4) \n",
    "gen4_out = Activation('relu')(gen4_BN)\n",
    "\n",
    "gen5 = Conv3DTranspose(filters[0], kernel_size=3, strides=(1,1,1), padding='same', data_format='channels_first')(gen4_out)\n",
    "gen5_BN = BatchNormalization()(gen5) \n",
    "gen5_out = Activation('relu')(gen5_BN)\n",
    "\n",
    "#128\n",
    "gen6 = Conv3DTranspose(filters[5], kernel_size=4, strides=(2,2,2), padding='same', name='gen6', data_format='channels_first')(gen5_out)\n",
    "gen6_BN = BatchNormalization()(gen6) \n",
    "gen6_out = Activation('relu')(gen6_BN)\n",
    "\n",
    "gen7= Conv3DTranspose(filters[5], kernel_size=3, strides=(1,1,1), padding='same', data_format='channels_first')(gen6_out)   #128\n",
    "gen7_BN = BatchNormalization()(gen7) \n",
    "gen7_out = Activation('relu')(gen7_BN)\n",
    "\n",
    "#64\n",
    "gen8 = Conv3DTranspose(filters[6], kernel_size=4, strides=(2,2,2), padding='same', name='gen8', data_format='channels_first')(gen7_out)\n",
    "gen8_BN = BatchNormalization()(gen8) \n",
    "gen8_out = Activation('relu')(gen8_BN)\n",
    "\n",
    "gen9= Conv3DTranspose(filters[6], kernel_size=3, strides=(1,1,1), padding='same', data_format='channels_first')(gen8_out)    #64\n",
    "gen9_BN = BatchNormalization()(gen9) \n",
    "gen9_out = Activation('relu')(gen9_BN)\n",
    "\n",
    "#############Transforming#####################\n",
    "gen10 = Conv3DTranspose(1, kernel_size=1, padding='same', name='g10', data_format='channels_first')(gen9_out)\n",
    "gen11 = squeeze(gen10, 1)\n",
    "gen12 = Conv2D(depth, kernel_size=1, padding='same', name='g12', data_format='channels_first')(gen11)\n",
    "# gen13 = gen12[0,:,:,:]\n",
    "# gen13 = reshape(gen13,[280,128,128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gPiyuc435Cs8"
   },
   "outputs": [],
   "source": [
    "autoEncGen = Model(inputs=inputImg, outputs=gen12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YWH-Z6dU5Cs9",
    "outputId": "4cdd9dba-52ad-4a32-8695-9e921c638348"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_img (InputLayer)          [(None, 1, 128, 128) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 192, 64, 64)  3264        input_img[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 192, 64, 64)  256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 192, 64, 64)  0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 192, 64, 64)  331968      activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 192, 64, 64)  256         conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 192, 64, 64)  0           activation[0][0]                 \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 192, 64, 64)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv3 (Conv2D)                  (None, 384, 32, 32)  1180032     activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 384, 32, 32)  128         conv3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 384, 32, 32)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4 (Conv2D)                  (None, 384, 32, 32)  1327488     activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 384, 32, 32)  128         conv4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 384, 32, 32)  0           activation_2[0][0]               \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 384, 32, 32)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv5 (Conv2D)                  (None, 768, 16, 16)  4719360     activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 768, 16, 16)  64          conv5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 768, 16, 16)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv6 (Conv2D)                  (None, 768, 16, 16)  5309184     activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 768, 16, 16)  64          conv6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 768, 16, 16)  0           activation_4[0][0]               \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 768, 16, 16)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv7 (Conv2D)                  (None, 1536, 8, 8)   18875904    activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 1536, 8, 8)   32          conv7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 1536, 8, 8)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv8 (Conv2D)                  (None, 1536, 8, 8)   21235200    activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 1536, 8, 8)   32          conv8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 1536, 8, 8)   0           activation_6[0][0]               \n",
      "                                                                 batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 1536, 8, 8)   0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv9 (Conv2D)                  (None, 3072, 4, 4)   75500544    activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 3072, 4, 4)   16          conv9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 3072, 4, 4)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv10 (Conv2D)                 (None, 3072, 4, 4)   84937728    activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 3072, 4, 4)   16          conv10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 3072, 4, 4)   0           activation_8[0][0]               \n",
      "                                                                 batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 3072, 4, 4)   0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "trans1 (Conv2D)                 (None, 3072, 4, 4)   9440256     activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 1536, 2, 4, 4 0           trans1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "trans_out (Conv3D)              (None, 1536, 2, 4, 4 2360832     reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gen1 (Conv3DTranspose)          (None, 768, 4, 8, 8) 75498240    trans_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 768, 4, 8, 8) 32          gen1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 768, 4, 8, 8) 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "gen2 (Conv3DTranspose)          (None, 384, 8, 16, 1 18874752    activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 384, 8, 16, 1 64          gen2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 384, 8, 16, 1 0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "gen3 (Conv3DTranspose)          (None, 384, 8, 16, 1 3981696     activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 384, 8, 16, 1 64          gen3[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 384, 8, 16, 1 0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "gen4 (Conv3DTranspose)          (None, 192, 16, 32,  4718784     activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 192, 16, 32,  128         gen4[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 192, 16, 32,  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_transpose (Conv3DTranspo (None, 192, 16, 32,  995520      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 192, 16, 32,  128         conv3d_transpose[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 192, 16, 32,  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "gen6 (Conv3DTranspose)          (None, 96, 32, 64, 6 1179744     activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 96, 32, 64, 6 256         gen6[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 96, 32, 64, 6 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_transpose_1 (Conv3DTrans (None, 96, 32, 64, 6 248928      activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 96, 32, 64, 6 256         conv3d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 96, 32, 64, 6 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "gen8 (Conv3DTranspose)          (None, 48, 64, 128,  294960      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 48, 64, 128,  512         gen8[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 48, 64, 128,  0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_transpose_2 (Conv3DTrans (None, 48, 64, 128,  62256       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 48, 64, 128,  512         conv3d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 48, 64, 128,  0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "g10 (Conv3DTranspose)           (None, 1, 64, 128, 1 49          activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Squeeze (TensorFlow [(None, 64, 128, 128 0           g10[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "g12 (Conv2D)                    (None, 50, 128, 128) 3250        tf_op_layer_Squeeze[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 331,082,883\n",
      "Trainable params: 331,081,411\n",
      "Non-trainable params: 1,472\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoEncGen.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e8_H6H0y5Cs_",
    "outputId": "6efdb515-354c-4119-f946-6e87a5902ce1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'g12/BiasAdd:0' shape=(None, 50, 128, 128) dtype=float32>"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zuIlI_e95CtB"
   },
   "source": [
    "### Optimizer, checkpoints and model fitting\n",
    "Here, we will define the loss function with other options like batch_size, no. of epochs, validation_split etc. We will also create checkpoints after certain no. of iteration. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X5JKAYtlA0Bo"
   },
   "source": [
    "Create a custom loss function considering both `mse` and `psnr` <br>\n",
    "** Uncomment if you want to use custom loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZtBZlj8xBIII"
   },
   "outputs": [],
   "source": [
    "# This loss function is for batch_size=1\n",
    "'Functions used in metrics'\n",
    "# @tf.function\n",
    "def metrics_psnr(gt, pred):\n",
    "    gt = tf.image.convert_image_dtype(gt, tf.float32)\n",
    "    pred = tf.image.convert_image_dtype(pred, tf.float32)\n",
    "    psnr_pred = tf.image.psnr(gt, pred, max_val = 1)\n",
    "\n",
    "    return psnr_pred\n",
    "\n",
    "# @tf.function\n",
    "def metrics_mse(gt, pred):\n",
    "    gt = tf.image.convert_image_dtype(gt, tf.float32)\n",
    "    pred = tf.image.convert_image_dtype(pred, tf.float32)\n",
    "    # mse_pred = tf.divide(tf.reduce_sum(tf.pow(tf.subtract(gt,pred),2.0)), tf.cast(tf.size(gt), tf.float32))\n",
    "    mse_pred = tf.reduce_mean(tf.square(tf.subtract(gt, pred))) \n",
    "\n",
    "    return mse_pred  \n",
    "\n",
    "'Loss function'\n",
    "# @tf.function\n",
    "def mse_psnr_loss(gt, pred):\n",
    "    gt = tf.image.convert_image_dtype(gt, tf.float32)\n",
    "    pred = tf.image.convert_image_dtype(pred, tf.float32)\n",
    "    # mse_pred = tf.divide(tf.reduce_sum(tf.pow(tf.subtract(gt,pred),2.0)), tf.cast(tf.size(gt), tf.float32))\n",
    "    mse_pred = tf.reduce_mean(tf.square(tf.subtract(gt, pred))) \n",
    "\n",
    "    psnr_pred = tf.image.psnr(gt, pred, max_val = 1)\n",
    "    psnr_pred = psnr_pred/100\n",
    "    psnr_pred = 1 - psnr_pred\n",
    "    \n",
    "    return mse_pred+psnr_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z24REiEi5CtC"
   },
   "outputs": [],
   "source": [
    "op = tf.keras.optimizers.Adam(learning_rate = 0.001)\n",
    "autoEncGen.compile(op,\n",
    "                    loss='mean_squared_error',\n",
    "                    metrics=['accuracy']\n",
    "                    # metrics=['accuracy', metrics_psnr, metrics_mse]                   \n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NMBXQmec5CtD"
   },
   "source": [
    "Now, we will set the `learning rate` to reduce when there is no change in `val_loss` for a certain period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OKyjMmmJ5CtE"
   },
   "outputs": [],
   "source": [
    "# Reducing learning rate\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                              factor=0.5,\n",
    "                              patience=10,\n",
    "                              min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GtPYtRRI5CtF"
   },
   "source": [
    "We will create `checkpoints` to store the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9y6xupHX5CtG",
    "outputId": "8678274d-506a-4d8b-f016-4ad12d1c2f59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "# Create checkpoint\n",
    "checkpoint_path = \"/content/drive/My Drive/3Dreconstruction/checkpoints2/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "cp_callback = ModelCheckpoint(checkpoint_path,\n",
    "                              monitor = 'val_loss',\n",
    "                              verbose = 1,\n",
    "                              save_best_only=False,\n",
    "                              save_weights_only=False,\n",
    "                              period=10)                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = autoEncGen.fit(x=X_train, \n",
    "                y=target, \n",
    "                batch_size=1,\n",
    "                epochs=100,\n",
    "                shuffle=True,\n",
    "                validation_split = 0.2,\n",
    "                #validation_data=(X_test, X_test)\n",
    "                callbacks = [reduce_lr, cp_callback]\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZImcUniZ5CtK"
   },
   "outputs": [],
   "source": [
    "#-----> Uncomment to save model \n",
    "# autoEncGen.save(\"xRay-autoencoder-v10_7.model\", save_format='tf') #save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nTAZOdDD5CtM"
   },
   "outputs": [],
   "source": [
    "#-----> Uncomment ot load model \n",
    "# model = load_model(\"xRay-autoencoder-v10_6.model\",\n",
    "#                    custom_objects={'mse_psnr_loss':mse_psnr_loss, \n",
    "#                                    'metrics_psnr': metrics_psnr,\n",
    "#                                    'metrics_mse': metrics_mse}, ) #load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r6HOLU1Z5CtO"
   },
   "outputs": [],
   "source": [
    "# encoded_imgs = encoder.predict(X_test)\n",
    "# predicted = autoencoder.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VNTxGbiG5CtP"
   },
   "source": [
    "## Plotting\n",
    "We will now plot training loss and validation loss. Then, we will save the figure in png format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kX82Li8i5CtS"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('mse_loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training loss', 'validation loss'], loc = 'upper right')\n",
    "\n",
    "plt.savefig('model_loss.png')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "xRay_autoencoder_v10_8.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
